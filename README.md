# Mobile-Money-Fraud-Detection

This project explores a **hybrid approach to fraud detection** by combining **supervised machine learning models** (Random Forest, XGBoost) with an **unsupervised Autoencoder (AE)** to detect anomalies.  
The goal is to improve detection of fraudulent transactions that traditional models might miss while maintaining high overall accuracy.

---

## ğŸ§­ Project Overview

**Objective:**  
To build a hybrid fraud detection pipeline capable of identifying both known and unknown fraud patterns using structured transaction data.

**Core Idea:**  
1. **Supervised Models** (Random Forest, XGBoost) â€” learn from labeled data to classify known fraud patterns.  
2. **Unsupervised Model** (Autoencoder) â€” reconstructs normal transactions; high reconstruction error flags potential anomalies.  
3. **Hybrid Integration** â€” combines predictions and anomaly flags for improved overall detection accuracy.

---

## ğŸ“ Repository Structure

```

fraud-detection-hybrid-ml/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ README.md                  # Brief note on data sources and preprocessing
â”‚   â””â”€â”€ sample_data.csv            # code loads data directly from kaggle directory
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_EDA_and_Feature_Engineering.ipynb
â”‚   â”œâ”€â”€ 2_Supervised_Learning_Models.ipynb
â”‚   â”œâ”€â”€ 3_Unsupervised_Autoencoder.ipynb
â”‚   â””â”€â”€ 4_Hybrid_Model_Integration.ipynb
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ xgboost_model.pkl
â”‚   â”œâ”€â”€ autoencoder_model.h5
â”‚   â””â”€â”€ random_forest_model.pkl       
â”‚
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ train_supervised.py
â”‚   â”œâ”€â”€ train_autoencoder.py
â”‚   â””â”€â”€ evaluate_hybrid.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE  (optional)

````

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/<Kwesisbits>/fraud-detection-hybrid-ml.git
cd fraud-detection-hybrid-ml
````

### 2. Create and Activate a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate       # for macOS/Linux
venv\Scripts\activate          # for Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

Example `requirements.txt`:

```
numpy
pandas
scikit-learn
xgboost
tensorflow
matplotlib
seaborn
joblib
```

### 4. Launch Jupyter/Colab

You can open and run the notebooks in:

* Google Colab (recommended)
* JupyterLab / VS Code notebooks

---

## ğŸ““ Notebook Overview

| Notebook                                | Purpose                                                                                                                                 | Key Outputs                                                       |
| --------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- |
| **1_EDA_and_Feature_Engineering.ipynb** | Explore dataset, visualize fraud distribution, and engineer new features (e.g., transaction velocity, amount ratios).                   | Cleaned & scaled datasets (`X_train_full_scaled`, `y_train_full`) |
| **2_Supervised_Learning_Models.ipynb**  | Train and evaluate Random Forest & XGBoost classifiers using class imbalance techniques (SMOTE, weighted loss).                         | `xgboost_model.pkl`                                               |
| **3_Unsupervised_Autoencoder.ipynb**    | Build and train an Autoencoder to detect anomalous transactions via reconstruction error.                                               | `autoencoder_model.h5`                                            |
| **4_Hybrid_Model_Integration.ipynb**    | Combine the AE anomaly scores with supervised predictions for a hybrid detection pipeline. Evaluate ROC-AUC, precision, recall, and F1. | `hybrid_results.json`                                             |

---

## ğŸ’¾ Model Saving Commands

Each notebook saves its outputs automatically.
You can add or verify the following lines near the end of your notebooks:

```python
import os, joblib, json
os.makedirs("models", exist_ok=True)

# Save Supervised Model
joblib.dump(xgb, "models/xgboost_model.pkl")

# Save Autoencoder
autoencoder.save("models/autoencoder_model.h5")


```

---

## ğŸ“Š Evaluation Metrics

The hybrid system is evaluated using:

* **ROC-AUC** â€” overall model discrimination
* **Precision & Recall** â€” focus on minimizing false positives/negatives
* **F1 Score** â€” harmonic mean of precision and recall
* **Confusion Matrix** â€” visual comparison between predicted and actual fraud

---

## ğŸš€ Results Summary

| Model            | ROC-AUC   | Precision | Recall   | F1 Score                |
| ---------------- | --------- | --------- | -------- | ----------------------- |
| Random Forest    | ~0.93     | 0.89      | 0.29     | 0.43                    |
| XGBoost          | ~0.95     | 0.91      | 0.33     | 0.48                    |
| Autoencoder      | â€”         | â€”         | â€”        | Anomaly threshold-based |
| **Hybrid Model** | **~0.97** | **0.90**  | **0.36** | **0.51**                |

*(Values are approximate â€” may vary depending on data splits.)*

---

## ğŸ“ˆ Future Improvements

* Integrate explainability with **SHAP** or **LIME** for model interpretation.
* Deploy as an **API** using FastAPI or Streamlit.
* Implement **online learning** for continuous fraud pattern updates.

---

## ğŸ§  Key Learnings

* Combining unsupervised and supervised approaches improves rare-event detection.
* Autoencoders can successfully identify subtle fraud anomalies missed by traditional models.
* Feature scaling, imbalance handling, and threshold tuning are critical for fraud detection accuracy.

---

## ğŸ§‘â€ğŸ’» Author

**Nana Kwesi Amponsah**
AI Engineer | Data Science
ğŸ“ Ghana
ğŸ“§ [nanaamponsah391@gmail.com](mailto:nanaamponsah391@gmail.com)
ğŸ”— [LinkedIn](https://www.linkedin.com/in/nana-kwesi-amponsah/) | [GitHub](https://github.com/<Kwesisbits>)

---

## ğŸªª License

This project is released under the [MIT License](LICENSE).

---

> â€œFraud detection is not just about finding anomalies â€” itâ€™s about learning what *normal* looks like.â€

```

